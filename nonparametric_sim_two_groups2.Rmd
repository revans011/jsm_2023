---
title: "R Notebook"
output: html_notebook
---

This is a simple two group simulaton for PU data. 

There are two groups, called case and control

The idea is to get some idea of how sample size, group imbalance, and non-detection affects statistical decisions via p-values.

```{r}
#install.packages("pacman")
pacman::p_load(
       data.table, # to group and clean data
       tidyverse,  # allows use of pipe (%>%) function in this chapter
       janitor,     #for clean_names and tabyl
       broom,   #tidy output, use tidy(xxx)
       gtsummary,  #nice tables
       magrittr, # for %<>%
       effectsize,
       rstatix,
        kableExtra
   ) 
```


make the data and run it
```{r}
# n.cases <- 100       #we know this
# n.controls.unlabeled <- 50 #we wish this
# 
# prop.nondetect <- 0.2
# 
# n.nondetect <- round(0.1*n.controls.unlabeled)
# 
# trt.eff <- .1
# 
# out <- NULL
# 
# for (i in 1:10){
# df <- data.frame(
# real.labels = c(rep(1,(n.cases+n.nondetect))
#                  ,rep(0,(n.controls.unlabeled-n.nondetect))),
# labelz = c(rep(1,n.cases),rep(0,n.controls.unlabeled)),
# dat = c(rnorm(n.cases+n.nondetect,mean=trt.eff)
#         ,rnorm((n.controls.unlabeled-n.nondetect)
#                        ,mean = 0)))
# 
# out <- c(out,c(wilcox_test(data=df,dat ~ labelz)$p
# ,wilcox_test(data=df,dat ~ real.labels)$p))
# }

```



```{r}

sim.fun<-function(num.iter = NULL
                  ,n.cases = NULL    
                  ,n.controls.unlabeled = NULL          
                  ,prop.nondetect = NULL
                  ,trt.eff = NULL){
out1 <- NULL
out2 <- NULL
out3 <- NULL

n.nondetect <- round(prop.nondetect*n.controls.unlabeled)

for (i in 1:num.iter){
df <- data.frame(
real.labels = c(rep(1,(n.cases+n.nondetect))
                 ,rep(0,(n.controls.unlabeled-n.nondetect))),
labelz = c(rep(1,n.cases),rep(0,n.controls.unlabeled)),
dat = c(rnorm(n.cases+n.nondetect,mean=trt.eff)
        ,rnorm((n.controls.unlabeled-n.nondetect)
                       ,mean = 0)))

out1 <- c(out1,wilcox_test(data=df,dat ~ labelz)$p)
out2 <- c(out2,wilcox_test(data=df,dat ~ real.labels)$p)

#out3 <- c(out3,cohens_d(x=df$dat[df$labelz==1],y=df$dat[df$labelz==0])[[1]])
out3 <- c(out3,(mean(df$dat[df$labelz==1])-mean(df$dat[df$labelz==0])))
}


return(data.frame(n.cases=n.cases,
                  n.controls.unlabeled=n.controls.unlabeled,
                  n.cntl.tru=(n.controls.unlabeled-n.nondetect),
                  n.nondetect=n.nondetect,
                  pu=out1,
                  tru=out2,
                  cohend = out3))
}


                    
```



```{r}
# sim.fun(num.iter=50
#                   ,n.cases = 100       #we know this
#                   ,n.controls.unlabeled = 50            #we wish new this
#                   ,prop.nondetect = 0.2
#                   ,trt.eff = .1)
```



```{r}
 now<-Sys.time()
# a<-50
# b<-100
# c<-200
# d<-300
# 
# contrl<-list(a,a,a,a,a,b,c,d,d,d)
# case<-  list(a,b,c,d,a,a,a,a,d,d)

contrl<-c(225,seq(50,400,by=50))
case<-c(225,rev(seq(50,400,by=50)))
contrl<-list(50,100,150,175,25)
case<-  list(150,100,50,25,175)
contrl<-list(350,50,300,100,250,150,200)
case<-  list(50,350,100,300,150,250,200)

# contrl<-list(50,50,100,25,100)
# case<-  list(50,100,50,100,25)
#--------------------------------------------

# control<-unlist(contrl)
# case<-unlist(case)
#a simulation

oddsratio_to_d(2,log=FALSE)

foo<-map2(contrl,case,\(contrl,case) sim.fun(num.iter=1000
                  ,n.cases = case       #we know this
                  ,n.controls.unlabeled = contrl            #we wish new this
                  ,prop.nondetect = 0.2
                  ,trt.eff = .1)) 

goo <- bind_rows(foo, .id = "column_label")  #unlists and binds rows


zoo <- goo %>% group_by(cases=n.cases
                        ,contrlz=n.controls.unlabeled) %>% 
  dplyr::summarise(cntl.tru=median(n.cntl.tru)
                   ,ndet=median(n.nondetect)
                   ,cohen=median(cohend)
                   ,p.pu=median(pu)
                   ,p.tru=median(tru)
                   ,pdiff=median(abs(pu-tru))
                   ) 
zoo %>% arrange(desc(pdiff)) %>% kable() %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(cohen)) %>% kable() %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(ndet)) %>% kable() %>% kable_styling(full_width = FALSE)
  

difftime(Sys.time(),now)
```

ndet
imbalance 
obs effect size
if ndet and imbalance combine to make small effect size


Note that n.nondetect changes the observed effect size because the means change.

some sample size patterns are better at finding effects size. This matters because there are many effect sizes in GWAS. S

0.5 is large treatment effect => all small p's for all sample sizes
for a large effect size symetric sample sizes make smaller differences between models
n.nondetect plays less role, but the imbalance plays a large role

0.1 is small treatment effect => all large p's for all sample sizes
n.detect plays a large role 

0.2 is mixed treatment effect => all small p's for all sample sizes
??? What is happening



