---
---
title: "sim"
author: Report by Rich Evans
date: 2023
output: 
  html_document:
     number_sections: true


---

This is a simple two group simulaton for PU data. 

There are two groups, called case and control

The idea is to get some idea of how sample size, group imbalance, and non-detection affects statistical decisions via p-values.

```{r,include=FALSE}
#install.packages("pacman")
pacman::p_load(
       data.table, # to group and clean data
       tidyverse,  # allows use of pipe (%>%) function in this chapter
       janitor,     #for clean_names and tabyl
       broom,   #tidy output, use tidy(xxx)
       gtsummary,  #nice tables
       magrittr, # for %<>%
       effectsize,
       rstatix,
        kableExtra
   ) 
```




```{r,include=FALSE}

sim.fun<-function(num.iter = NULL
                  ,n.cases = NULL    
                  ,n.controls.unlabeled = NULL          
                  ,prop.nondetect = NULL
                  ,trt.eff = NULL){
out1 <- NULL
out2 <- NULL
out3 <- NULL

n.nondetect <- round(prop.nondetect*n.controls.unlabeled)

for (i in 1:num.iter){
df <- data.frame(
real.labels = c(rep(1,(n.cases+n.nondetect))
                 ,rep(0,(n.controls.unlabeled-n.nondetect))),
labelz = c(rep(1,n.cases),rep(0,n.controls.unlabeled)),
dat = c(rnorm(n.cases+n.nondetect,mean=trt.eff)
        ,rnorm((n.controls.unlabeled-n.nondetect)
                       ,mean = 0)))

out1 <- c(out1,wilcox_test(data=df,dat ~ labelz)$p)
out2 <- c(out2,wilcox_test(data=df,dat ~ real.labels)$p)

out3 <- c(out3,effectsize::cohens_d(x=df$dat[df$labelz==1][[1]],y=df$dat[df$labelz==0])[[1]])
#out3 <- c(out3,(mean(df$dat[df$labelz==1])-mean(df$dat[df$labelz==0])))
}


return(data.frame(n.cases=n.cases,
                  n.controls.unlabeled=n.controls.unlabeled,
                  n.case.tru = (n.cases+n.nondetect),
                  n.cntl.tru=(n.controls.unlabeled-n.nondetect),
                  n.nondetect=n.nondetect,
                  pu=out1,
                  tru=out2,
                  cohend = out3))
}


                    
```



```{r}
 now<-Sys.time()
# a<-50
# b<-100
# c<-200
# d<-300
# 
# contrl<-list(a,a,a,a,a,b,c,d,d,d)
# case<-  list(a,b,c,d,a,a,a,a,d,d)

contrl<-c(225,seq(50,400,by=50))
case<-c(225,rev(seq(50,400,by=50)))
contrl<-list(50,100,150,175,25)
case<-  list(150,100,50,25,175)
contrl<-list(350,50,300,100,250,150,200)
case<-  list(50,350,100,300,150,250,200)

# contrl<-list(50,50,100,25,100)
# case<-  list(50,100,50,100,25)

foo<-map2(contrl,case,\(contrl,case) sim.fun(num.iter=1500
                  ,n.cases = case       #we know this
                  ,n.controls.unlabeled = contrl            #we wish new this
                  ,prop.nondetect = .1
                  ,trt.eff = .1)) 

goo <- bind_rows(foo, .id = "column_label")  #unlists and binds rows


zoo <- goo %>% group_by(cases=n.cases
                        ,contrlz=n.controls.unlabeled) %>% 
  dplyr::summarise(case.tru=median(n.case.tru)
                   ,cntl.tru=median(n.cntl.tru)
                   ,cas_ctrl_difz=median(cases-n.controls.unlabeled)
                   ,cas_ctrl_diftru=median(n.case.tru-n.cntl.tru)
                   ,casz_casetru=median(n.cases-n.case.tru)
                   ,n.nodetec=median(n.nondetect)
                   ,cohen=median(cohend)
                   ,p.pu=median(pu)
                   ,p.tru=median(tru)
                   ,pdiff=median(abs(pu-tru))
                   ) 
zoo %>% arrange(desc(pdiff)) %>% 
  kable(caption = "pdiff ") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(cohen)) %>% 
  kable(caption = "cohen ") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(n.nodetec)) %>% 
  kable(caption = "number non detected ") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(p.pu)) %>% 
  kable(caption = "p.pu ") %>% kable_styling(full_width = FALSE)

oddsratio_to_d(2,log=FALSE) #this coverts OR to cohens so that I make this like SNPs data
difftime(Sys.time(),now)
```


Small effect size: The designs have to line up to get less bias
with prop=.1 and eff=.1, n.iter = 1500
bias IMPROVES as designs match up. That is pdiff gets smaller as n.nodetec gets smaller and as
case-case goes from -35 to -5

In other words, the initial design must be such that shifting non-detected positives has little impact
that means, more cases than controls.


```{r}
 now<-Sys.time()


num.iter <- 15
prop.nondetect <- 0.2
trt.ef<-c(.38,.15,.1)

foo<-map2(contrl,case,\(contrl,case) sim.fun(num.iter=num.iter
                  ,n.cases = case       #we know this
                  ,n.controls.unlabeled = contrl            #we wish new this
                  ,prop.nondetect = prop.nondetect
                  ,trt.eff = trt.ef[1])) 

goo <- bind_rows(foo, .id = "column_label")  #unlists and binds rows


zoo <- goo %>% group_by(cases=n.cases
                        ,contrlz=n.controls.unlabeled) %>% 
  dplyr::summarise(cntl.tru=median(n.cntl.tru)
                   ,ndet=median(n.nondetect)
                   ,cohen=median(cohend)
                   ,p.pu=median(pu)
                   ,p.tru=median(tru)
                   ,pdiff=median(abs(pu-tru))
                   ) 
zoo %>% arrange(desc(pdiff)) %>% 
  kable(caption = "pdiff large eff") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(cohen)) %>% 
  kable(caption = "cohen large eff") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(ndet)) %>% 
  kable(caption = "number non detected large eff") %>% kable_styling(full_width = FALSE)
  
#------------------------------------------------

foo<-map2(contrl,case,\(contrl,case) sim.fun(num.iter=num.iter
                  ,n.cases = case       #we know this
                  ,n.controls.unlabeled = contrl            #we wish new this
                  ,prop.nondetect = prop.nondetect
                  ,trt.eff = trt.ef[3])) 

goo <- bind_rows(foo, .id = "column_label")  #unlists and binds rows


zoo <- goo %>% group_by(cases=n.cases
                        ,contrlz=n.controls.unlabeled) %>% 
  dplyr::summarise(cntl.tru=median(n.cntl.tru)
                   ,ndet=median(n.nondetect)
                   ,cohen=median(cohend)
                   ,p.pu=median(pu)
                   ,p.tru=median(tru)
                   ,pdiff=median(abs(pu-tru))
                   ) 
zoo %>% arrange(desc(pdiff)) %>% 
  kable(caption = "pdiff medium eff") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(cohen)) %>% 
  kable(caption = "cohen medium eff") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(ndet)) %>% 
  kable(caption = "number non detected medium eff") %>% kable_styling(full_width = FALSE)
#-------------------------------------------------


foo<-map2(contrl,case,\(contrl,case) sim.fun(num.iter=num.iter
                  ,n.cases = case       #we know this
                  ,n.controls.unlabeled = contrl            #we wish new this
                  ,prop.nondetect = prop.nondetect
                  ,trt.eff = trt.ef[3])) 

goo <- bind_rows(foo, .id = "column_label")  #unlists and binds rows


zoo <- goo %>% group_by(cases=n.cases
                        ,contrlz=n.controls.unlabeled) %>% 
  dplyr::summarise(cntl.tru=median(n.cntl.tru)
                   ,ndet=median(n.nondetect)
                   ,cohen=median(cohend)
                   ,p.pu=median(pu)
                   ,p.tru=median(tru)
                   ,pdiff=median(abs(pu-tru))
                   ) 
zoo %>% arrange(desc(pdiff)) %>% 
  kable(caption = "pdiff small eff") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(cohen)) %>% 
  kable(caption = "cohen small eff") %>% kable_styling(full_width = FALSE)
zoo %>% arrange(desc(ndet)) %>% 
  kable(caption = "number non detected small eff") %>% kable_styling(full_width = FALSE)

difftime(Sys.time(),now)
```

ndet
imbalance 
obs effect size
if ndet and imbalance combine to make small effect size


Note that n.nondetect changes the observed effect size because the means change.

some sample size patterns are better at finding effects size. This matters because there are many effect sizes in GWAS. S

0.5 is large treatment effect => all small p's for all sample sizes
for a large effect size symetric sample sizes make smaller differences between models
n.nondetect plays less role, but the imbalance plays a large role

0.1 is small treatment effect => all large p's for all sample sizes
n.detect plays a large role 

0.2 is mixed treatment effect => all small p's for all sample sizes
??? What is happening



